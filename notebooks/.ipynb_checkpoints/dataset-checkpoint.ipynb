{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import datetime\n",
    "\n",
    "import xmltodict as xd\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# lets make a little data set for fun...\n",
    "mh_dir = os.path.abspath('../db/mh_data/')\n",
    "mh_cases = glob.glob(os.path.join(mh_dir, '*'))\n",
    "\n",
    "class Input: # an input struct\n",
    "    pass\n",
    "\n",
    "db = [] # list of all input structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xml_parser(xml_path):\n",
    "\n",
    "    with open(xml_path) as fd:\n",
    "            doc = xd.parse(fd.read())\n",
    "            fd.close()\n",
    "\n",
    "    raw_db = doc['anaesthetic']['data']['var']\n",
    "    print(\"FILE READ\")\n",
    "\n",
    "\n",
    "    for i in raw_db[3:]:\n",
    "        name = i['vaname']\n",
    "\n",
    "        times = str(i['vatimes']).replace('None','000000').split(',')\n",
    "        values = str(i['vavalues']).replace('NA','nan').split(',')\n",
    "\n",
    "        times = np.asarray(times)\n",
    "        values = np.asarray(values).astype('float')\n",
    "\n",
    "        var_df = pd.DataFrame(data = {'time' : times, name : values})\n",
    "\n",
    "        if 'full_df' in locals():\n",
    "            full_df = full_df.join(var_df.set_index('time'), on='time')\n",
    "        else:\n",
    "            full_df = var_df\n",
    "\n",
    "    print(\"XML PARSED\")\n",
    "\n",
    "    return full_df\n",
    "\n",
    "def delta_spo2(spo2_arr):\n",
    "    # compute the difference between the maximum value \n",
    "    max_val = max(spo2_arr)\n",
    "    min_val = min(spo2_arr)\n",
    "    d = max_val - min_val\n",
    "\n",
    "    return d\n",
    "\n",
    "# a sample will be 6 entries (=60 seconds) of every datapoint to determine if\n",
    "# there will be a change in spo2 in the next 60 seconds\n",
    "# spo2, hr, \n",
    "def data_generator(patient_df):\n",
    "    # slice the df into array of 6 element dfs\n",
    "    interval_df = []\n",
    "\n",
    "    for i in range(patient_df.shape[0]):\n",
    "        if (i+1) % 6 == 0:\n",
    "            # split every 6 timestamp (60 seconds)\n",
    "            a = i - 5\n",
    "            interval_df.append(patient_df[a:i+1])\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    # compute spo2 delta\n",
    "    for i in range(len(interval_df)):\n",
    "        sample = Input()\n",
    "        sample.x = np.asarray(interval_df[i].unstack()) # vector of input data from \n",
    "        try:\n",
    "            sample.d = delta_spo2(interval_df[i+1]['spo2.SpO2'])\n",
    "        except:\n",
    "            print(\"end of dataset\")\n",
    "            break\n",
    "        # label\n",
    "        if sample.d > 0.011:\n",
    "            sample.y = 1\n",
    "        else:\n",
    "            sample.y = 0 \n",
    "        db.append(sample)\n",
    "\n",
    "    return db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse every xml file and save each to a separate h5 file for future use\n",
    "# spo2.SpO2, co2.et, ecg.hr, nibp.sys, nibp.dia\n",
    "def mk_npy():\n",
    "    for i in mh_cases:\n",
    "        print(i)\n",
    "        df = xml_parser(i)\n",
    "\n",
    "        # for all features simply use df\n",
    "        # spo2.SpO2, co2.et, ecg.hr, nibp.sys, nibp.dia\n",
    "        df2 = pd.DataFrame(df,\n",
    "                columns=['ecg.hr',\n",
    "                    'co2.et', 'nibp.sys',\n",
    "                    'nibp.dia', 'spo2.SpO2']\n",
    "                )\n",
    "\n",
    "        df2 = df2[np.abs(df2-df2.mean()) <= (3*df2.std())]\n",
    "        df2 = df2.dropna()\n",
    "\n",
    "        # scale the values between 1-0 the data by patient....\n",
    "        x = df2.values\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        x_scaled = min_max_scaler.fit_transform(x)\n",
    "        df2 = pd.DataFrame(x_scaled, columns=df2.columns)\n",
    "\n",
    "        data_generator(df2)\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for i in db:\n",
    "        X.append(i.x)\n",
    "        Y.append(i.y)\n",
    "\n",
    "    X = np.asarray(X).astype('float')\n",
    "    Y = np.asarray(Y).astype('int')\n",
    "    print(\"stable: \" + str(np.sum(Y == 0)))\n",
    "    print(\"unstable: \" + str(np.sum(Y == 1)))\n",
    "\n",
    "    np.save(\"x3.npy\", X)\n",
    "    np.save(\"y3.npy\", Y)\n",
    "\n",
    "\n",
    "\n",
    "mk_npy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
